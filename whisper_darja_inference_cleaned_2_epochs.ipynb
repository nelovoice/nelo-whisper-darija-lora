{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "whisper_darja_inference_cleaned (1)",
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "e08b51b6",
      "cell_type": "code",
      "source": [
        "# \ud83d\udce6 Install dependencies (if running on Colab or fresh environment)\n",
        "!pip install -q transformers datasets librosa jiwer\n"
      ],
      "metadata": {
        "id": "e08b51b6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:42:59.627267Z",
          "iopub.execute_input": "2025-07-17T11:42:59.627598Z",
          "iopub.status.idle": "2025-07-17T11:43:08.199287Z",
          "shell.execute_reply.started": "2025-07-17T11:42:59.627573Z",
          "shell.execute_reply": "2025-07-17T11:43:08.19798Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\u2705 GPU d\u00e9tect\u00e9 :\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError(\"\ud83d\udea8 GPU non disponible. Va dans le menu Ex\u00e9cution > Modifier le type d'ex\u00e9cution > GPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "553HtgdLSenc",
        "outputId": "a6e340af-032b-4226-a8db-4dd574e5c709"
      },
      "id": "553HtgdLSenc",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 GPU d\u00e9tect\u00e9 : Tesla T4\n"
          ]
        }
      ]
    },
    {
      "id": "bdc2dd08",
      "cell_type": "code",
      "source": [
        "# \u2705 Load Whisper model and processor\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "model_checkpoint = \"openai/whisper-small\"\n",
        "processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
        "model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)\n",
        "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"fr\", task=\"transcribe\")\n",
        "model.config.suppress_tokens = []\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdc2dd08",
        "outputId": "e91b3638-9c93-47e7-db64-739ca2ba7721",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:43:08.202624Z",
          "iopub.execute_input": "2025-07-17T11:43:08.202973Z",
          "iopub.status.idle": "2025-07-17T11:43:50.729254Z",
          "shell.execute_reply.started": "2025-07-17T11:43:08.202942Z",
          "shell.execute_reply": "2025-07-17T11:43:50.728261Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WhisperForConditionalGeneration(\n",
              "  (model): WhisperModel(\n",
              "    (encoder): WhisperEncoder(\n",
              "      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "      (embed_positions): Embedding(1500, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperEncoderLayer(\n",
              "          (self_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): WhisperDecoder(\n",
              "      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
              "      (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperDecoderLayer(\n",
              "          (self_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": 4
    },
    {
      "id": "0dd3a273",
      "cell_type": "code",
      "source": [
        "!pip install --upgrade \"fsspec<=2023.6.0\"\n",
        "!pip install -q datasets transformers accelerate torchaudio jiwer evaluate\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n",
        "\n",
        "# \ud83d\udd04 Load and clean dataset (Darija in Latin script)\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Replace with your actual dataset\n",
        "ds = load_dataset(\"atlasia/DODa-audio-dataset\", download_mode=\"force_redownload\")  # e.g., \"yourname/darja-dataset\"\n",
        "\n",
        "def is_valid(example):\n",
        "    txt = example.get(\"darija_Arab_new\")\n",
        "    return (\n",
        "        txt is not None and txt.strip() != \"\" and\n",
        "        example.get(\"audio\", {}).get(\"array\") is not None and\n",
        "        sum(example[\"audio\"][\"array\"]) != 0\n",
        "    )\n",
        "\n",
        "ds_cleaned = ds.filter(is_valid)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409,
          "referenced_widgets": [
            "ad5764049f3e41c0858bfb8b34074a69",
            "3a3bf181fd834ff69380893d2e833396",
            "e1be9f7d45ff48a1b41cf156557331b9",
            "c3f4dc1509be45e2a0edddd1af287ace",
            "87664767b73b4255b5ccf8a5eb04a3ef",
            "4b190b5edbb646859129d9957d83af46",
            "0d21dafea1a6411bac4fb6344133234a",
            "5728ad2fdd9e43fe8ddbdded441e5675",
            "33e45c420ccb464aab6f3f0d468ce42d",
            "3d7d7c40b80f4b5aa9bac2f292f85b26",
            "75bd99e8c1fa4722b278cf886dfa6dfd",
            "03a49b7775fd4f9eb7409ee8a73e66e8",
            "6567987aeb40434aa5481255ee41bb13",
            "89e26f2186fe449ebbdcd47af66ec402",
            "981b7396d06f4c7c80c8a8b98f300487",
            "3862724a1bd9442996e71eeb7c7fbde2",
            "934d6818f9ee4c3789833f93c0b4b287",
            "9e1eecc2d6b949668543927a6e1f2114",
            "077b092dfbec464bb2eb3638a2ff4f76",
            "34658c8fba5743b8851bb6566c61658a",
            "6ce969471c7c40c59681771abaa702a7",
            "998bb7cda7b6466a94f1bc4e4d46ca68",
            "809860011d7b440bb76d49fa24a068e7",
            "e574a76ce490401081b6da2fba849edc",
            "e0142be0e80a45338027fee6f783fb3b",
            "44205b0adc4442fd9edc0599c664dfa9",
            "1dd8713cba0848148e0f0386f4fff5da",
            "13ca6c1f1ea44cb8b4430e3267a5ddd6",
            "60ec043b7a5f4345981454eba6f632d2",
            "c1a745906360430c907e754c8605fccf",
            "8f078c274e9d45c497d728a7ff9140a2",
            "20890745167d4741a4981002c56a2da8",
            "0f25f70c644f46fb8c77b2e3c261c1ec",
            "ab721ab67e1a4e1e9ab0539d233a0712",
            "628525deeea34e2fa56c9214f7d2b613",
            "9fcd85abef49476293e99297a5d0ecca",
            "6a0e2a7fb1374dc3812c0a7d50f40bb8",
            "03c5a4a073a54e808f21493f42a2649b",
            "d1fc29c76a7e47f0b726fb2a5be4b187",
            "23a5c8ec9da54441b460e28bb0811c82",
            "8760d73e8e614be9ab14e466e01edaad",
            "14982c94d2c04af2993d35509593556e",
            "1cdb70b7b5ac485d9dffd62d8b3ca4ab",
            "9bcb13ec0a1346f3b5dc3563a1394199",
            "9e7fc5ad976e4fea8dc9a572fb817c54",
            "539329c403494b28a83ac67d9928b192",
            "d370debbcaca4cd9a4714ceaa0782f9f",
            "8bba8b2f2aa246168d7e80d60c06c656",
            "f72a88b90b4b44a2b4f42f7aa66360ff",
            "8d6574610e034153adaf6ea75bbf0bd3",
            "7cb4117339184d9092a600d6dc450e15",
            "f68d8a6a7fb24ac891c2469f4d7c3571",
            "83602ed2a6ed4632aa21c40da970cbfc",
            "507531f89db241b8b9e2a38d7aa49a42",
            "6fdca27cab314a4dbe88cc50aeb8871a",
            "c2642f08a734403aaf546a7cb98c7628",
            "b2856a96ce5844f4900d5635bfdfa2d6",
            "122d87d768514ffcad6467312fb11611",
            "59afb7fbd99749078452059a9bc4fcfe",
            "4093fa37d2ae4f51b531117e8b51dfdb",
            "e322cae95147499298bca26accbf2a6f",
            "52d29656e5134a8fb877eaabde9c0edd",
            "a7ee86e9fbf9431fa0c168a6506084d8",
            "9d63a287db4b48d9acaaae7a224a1b2e",
            "87c8e60d4a9b4d6c8104d565c6c90f1a",
            "5ff1d8702552415c8cb78957de349688",
            "1cc0a6c42bf34252b456d4abd317c9ef",
            "940e883ec6b74c1399e18c160b819c7f",
            "0940140f78f34134a550a46c8acc965c",
            "710caf529fb74c76a290fd539f46e524",
            "88d882c2ecb348c3861dd1fbf9b6b9bc",
            "33a2e411746e4a1b802d0f65edb460f9",
            "e0197c6357bd4a9a9fcdadc9cb5d28a0",
            "546b1d1bea7b49bf8471aaa9df655586",
            "9fc2b593fd684a7e95df1ad9ab61bf79",
            "8ad698215cb84a31aa32bf62de2880a3",
            "b1ec61e089e84cc38eb93e66203e0ae2",
            "e71c327de5874f8ab45a0ccafb1bb00c",
            "c43134bdba31480499db92d2ed8be1b6",
            "e647a5c272604a49af426d747ff490c4",
            "13e16bf729ff419d8f862c2d0124231a",
            "fdce43c9d91f45b1ab43e9db4fdaad2c",
            "81b2f21221064112b8c1a9214e1d9da4",
            "814ec0bada47432eadb2136a644f2cb1",
            "96737f5c25e842edbd4a6be1a814b47b",
            "d9357fcec6c94da58f6d154be2c0c025",
            "1b1558b9443a4ab8960cad360dd8fad6",
            "55ae58ed71d043eabd6a42255b0f184e",
            "03192f1508074d658aae086c7485c23d",
            "859ad258b5b24641b31c6fe92f52758d",
            "fa0f9a67a9e042b1a82a5f68644566a0",
            "ac74a97e784941fb8c52e011b566449d",
            "7381006067f849bab420e7b60f9d179e",
            "bf37e6a15a0f4713b08dadb8d1dd2e1a",
            "9ab71cfd82a144559e827130d9f44d42",
            "9819241beb3f4d45860dd2aad89ce703",
            "cfc39c6abdad4bb79a4338f5d82a4d56",
            "bb541b0157354de4b9f8a46b576994d2",
            "d4784cb752374b76831ac8ae93e63663",
            "500b93baae98437a95a86e2d17c89354",
            "44b46e8e416046358866923bfb6f8dd3",
            "3684131e67f0484e925bb9d3690aba89",
            "39a443bc2ed74ff485feca2be026aef3",
            "212ecc01069d4f39a870762954b747b2",
            "636bacef8ca0481d903cfd9ec3257b3e",
            "8b2531a8152342e79458a70b0e2e083b",
            "999f9002988f419585455e899bc45bb5",
            "ca55b209f5b54b5e9284bb556189df53",
            "79792ccd3a3e437b84ddea9c2fcccfd8",
            "1bda22089314491e91d572c357f7b623"
          ]
        },
        "id": "0dd3a273",
        "outputId": "4047fbd8-df02-4d20-8a00-28584c735f8e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:48:12.327862Z",
          "iopub.execute_input": "2025-07-17T11:48:12.328792Z",
          "iopub.status.idle": "2025-07-17T11:50:35.657509Z",
          "shell.execute_reply.started": "2025-07-17T11:48:12.328664Z",
          "shell.execute_reply": "2025-07-17T11:50:35.656312Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec<=2023.6.0 in /usr/local/lib/python3.11/dist-packages (2023.6.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.36k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5764049f3e41c0858bfb8b34074a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03a49b7775fd4f9eb7409ee8a73e66e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/333M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809860011d7b440bb76d49fa24a068e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/279M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab721ab67e1a4e1e9ab0539d233a0712"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/237M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e7fc5ad976e4fea8dc9a572fb817c54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/226M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2642f08a734403aaf546a7cb98c7628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/210M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc0a6c42bf34252b456d4abd317c9ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e71c327de5874f8ab45a0ccafb1bb00c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/12743 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03192f1508074d658aae086c7485c23d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/12743 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "500b93baae98437a95a86e2d17c89354"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "id": "832f4388",
      "cell_type": "code",
      "source": [
        "# \ud83c\udfaf Prepare a single sample for inference\n",
        "import torch\n",
        "\n",
        "# \u26a0\ufe0f Sp\u00e9cifier le split train\n",
        "example = ds_cleaned[\"train\"][0]\n",
        "\n",
        "# Pr\u00e9paration de l'entr\u00e9e audio\n",
        "input_features = processor(example[\"audio\"][\"array\"], sampling_rate=16000, return_tensors=\"pt\").input_features\n",
        "\n",
        "# G\u00e9n\u00e9ration avec le mod\u00e8le\n",
        "generated_ids = model.generate(\n",
        "    input_features.to(model.device),\n",
        "    max_length=128,\n",
        "    no_repeat_ngram_size=3,\n",
        "    forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        ")\n",
        "\n",
        "# Transcription\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "# Affichage\n",
        "print(\"\ud83d\udd0a Audio transcription:\", transcription)\n",
        "print(\"\ud83d\udcdd R\u00e9f\u00e9rence :\", example[\"darija_Arab_new\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832f4388",
        "outputId": "1fcf342f-3814-41eb-912f-1e83cca3b99a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:53:48.708905Z",
          "iopub.execute_input": "2025-07-17T11:53:48.710745Z",
          "iopub.status.idle": "2025-07-17T11:54:17.392323Z",
          "shell.execute_reply.started": "2025-07-17T11:53:48.710699Z",
          "shell.execute_reply": "2025-07-17T11:54:17.391281Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udd0a Audio transcription:  \u0647\u0645 \u0645\u062e\u0628\u0646\u0634\u064a \u062d\u0627\u062c\u0629 \u0623\u0646\u0627 \u0645\u062a\u0642\u0646\n",
            "\ud83d\udcdd R\u00e9f\u00e9rence : \u0647\u0648\u0645\u0627 \u0645\u062e\u0628\u064a\u064a\u0646 \u0634\u064a \u062d\u0627\u062c\u0629 \u0627\u0646\u0627 \u0645\u062a\u064a\u0642\u0646\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "id": "w2-K3_AlPqiv",
      "cell_type": "code",
      "source": [
        "# 5. Fonction de pr\u00e9traitement\n",
        "def prepare_dataset(example):\n",
        "    audio = example[\"audio\"]\n",
        "    example[\"input_features\"] = processor.feature_extractor(\n",
        "        audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]\n",
        "    ).input_features[0]\n",
        "    example[\"labels\"] = processor.tokenizer(\n",
        "        example[\"darija_Arab_new\"],\n",
        "        truncation=True,\n",
        "        max_length=225,\n",
        "        return_tensors=None\n",
        "    ).input_ids\n",
        "    return example\n",
        "\n",
        "# 6. Pr\u00e9traiter chaque split\n",
        "ds_preprocessed = {\n",
        "    split: ds_cleaned[split].map(\n",
        "        prepare_dataset,\n",
        "        remove_columns=ds_cleaned[split].column_names\n",
        "    )\n",
        "    for split in ds_cleaned\n",
        "}\n",
        "\n",
        "# 7. DataCollator personnalis\u00e9\n",
        "class WhisperDataCollator:\n",
        "    def __init__(self, processor):\n",
        "        self.processor = processor\n",
        "\n",
        "    def __call__(self, features):\n",
        "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
        "        labels = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
        "\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "        label_batch = self.processor.tokenizer.pad(labels, return_tensors=\"pt\")\n",
        "        batch[\"labels\"] = label_batch[\"input_ids\"].masked_fill(label_batch.attention_mask.ne(1), -100)\n",
        "        return batch\n",
        "\n",
        "# 8. Initialiser le DataCollator\n",
        "data_collator = WhisperDataCollator(processor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ac6612573f2e4931a67dae5984ff2b12",
            "c73af028fe094950913fed53d73e5195",
            "125ddece68f14a68b95fddc794256e8f",
            "fa55ed057c224cd4a701128f4d4a2a61",
            "5ff75532fb28419c8045a0c1a390310e",
            "e8f1e599b3ca40a68497648767e31f0e",
            "e823167ac74b4109ac19fb0397a426d9",
            "2e4ed086e7ca403292254723766eab9d",
            "9b2570b9159a491d848553ba6f1249ea",
            "6a1e2a3611194cd29cbbc22cb886c2d9",
            "0242d10d42d24260b41d46b619731c28"
          ]
        },
        "id": "w2-K3_AlPqiv",
        "outputId": "2fa919c5-c3f4-4e76-d523-5b4e92b797c9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:56:47.581973Z",
          "iopub.execute_input": "2025-07-17T11:56:47.582402Z",
          "iopub.status.idle": "2025-07-17T12:00:46.64684Z",
          "shell.execute_reply.started": "2025-07-17T11:56:47.582374Z",
          "shell.execute_reply": "2025-07-17T12:00:46.645415Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12720 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac6612573f2e4931a67dae5984ff2b12"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "id": "wAOkTB7sMah8",
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, Seq2SeqTrainingArguments\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "import types\n",
        "\n",
        "# Charger mod\u00e8le et config LoRA\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"k_proj\", \"v_proj\"]\n",
        ")\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "\n",
        "# Patcher base_model.forward pour supprimer input_ids et inputs_embeds\n",
        "base_forward = model.base_model.forward\n",
        "\n",
        "def base_model_forward_patch(self, *args, **kwargs):\n",
        "    for arg in [\"input_ids\", \"inputs_embeds\"]:\n",
        "        if arg in kwargs:\n",
        "            kwargs.pop(arg)\n",
        "    return base_forward(*args, **kwargs)\n",
        "\n",
        "model.base_model.forward = types.MethodType(base_model_forward_patch, model.base_model)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-darja-lora\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=1e-4,\n",
        "    warmup_steps=100,\n",
        "    num_train_epochs=2,     # <--- 2 epochs here\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\",\n",
        "    fp16=False,            # fp16 usually unsupported on CPU\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    remove_unused_columns=False,\n",
        "    dataloader_pin_memory=False,\n",
        ")\n",
        "\n",
        "\n",
        "# Cr\u00e9er Trainer (avec ton ds_preprocessed et data_collator d\u00e9finis)\n",
        "# Cr\u00e9er Trainer sans eval_dataset\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_preprocessed[\"train\"],  # \u2705 n\u00e9cessaire\n",
        "    data_collator=data_collator,             # \u2705 indispensable\n",
        ")\n",
        "\n",
        "\n",
        "# Lancer entra\u00eenement\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wAOkTB7sMah8",
        "outputId": "30b0b7cf-893d-4af8-bf22-3216110acdc6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T12:06:38.845818Z",
          "iopub.execute_input": "2025-07-17T12:06:38.846353Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3180/3180 3:34:37, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.528900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.736000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.613200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.598100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.588600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.527100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.523100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.543700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.524100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.477400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.479900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.463300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.475400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.474900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.456400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.421900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.403800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.413100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.399000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.394800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.418300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.417400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.409100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.412100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.364500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.393900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.384000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.399400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.373300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3180, training_loss=0.595494270324707, metrics={'train_runtime': 12883.4752, 'train_samples_per_second': 1.975, 'train_steps_per_second': 0.247, 'total_flos': 7.3740236488704e+18, 'train_loss': 0.595494270324707, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "id": "8fc9dc71-4551-43bd-a332-9e3722cba51f",
      "cell_type": "code",
      "source": [
        "# Dossier de sortie\n",
        "output_dir = \"./whisper-darja-lora-final\"\n",
        "\n",
        "# 1. Sauvegarder le mod\u00e8le LoRA\n",
        "model.save_pretrained(output_dir)\n",
        "\n",
        "# 2. Sauvegarder le processor (tokenizer + feature extractor)\n",
        "processor.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"\u2705 Mod\u00e8le et processor sauvegard\u00e9s dans : {output_dir}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.574671Z",
          "iopub.status.idle": "2025-07-17T11:45:28.574949Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.574811Z",
          "shell.execute_reply": "2025-07-17T11:45:28.574824Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fc9dc71-4551-43bd-a332-9e3722cba51f",
        "outputId": "d293e883-1222-42aa-83b9-23633984d842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Mod\u00e8le et processor sauvegard\u00e9s dans : ./whisper-darja-lora-final\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "id": "9a326c74-966c-4ea0-b929-a2221cd8040b",
      "cell_type": "code",
      "source": [
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# 1. Charger le processor\n",
        "processor = WhisperProcessor.from_pretrained(\"./whisper-darja-lora-final\")\n",
        "\n",
        "# 2. Charger le mod\u00e8le de base\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "# 3. Appliquer les poids LoRA sur le mod\u00e8le de base\n",
        "model = PeftModel.from_pretrained(base_model, \"./whisper-darja-lora-final\")\n",
        "\n",
        "# 4. Passer en eval mode si besoin\n",
        "model.eval()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.576256Z",
          "iopub.status.idle": "2025-07-17T11:45:28.576545Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.576403Z",
          "shell.execute_reply": "2025-07-17T11:45:28.576419Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a326c74-966c-4ea0-b929-a2221cd8040b",
        "outputId": "80288b67-0ce5-46ea-8b3b-6012ac67e8de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): WhisperForConditionalGeneration(\n",
              "      (model): WhisperModel(\n",
              "        (encoder): WhisperEncoder(\n",
              "          (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "          (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "          (embed_positions): Embedding(1500, 768)\n",
              "          (layers): ModuleList(\n",
              "            (0-11): 12 x WhisperEncoderLayer(\n",
              "              (self_attn): WhisperAttention(\n",
              "                (k_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (activation_fn): GELUActivation()\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): WhisperDecoder(\n",
              "          (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
              "          (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
              "          (layers): ModuleList(\n",
              "            (0-11): 12 x WhisperDecoderLayer(\n",
              "              (self_attn): WhisperAttention(\n",
              "                (k_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (activation_fn): GELUActivation()\n",
              "              (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (encoder_attn): WhisperAttention(\n",
              "                (k_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (v_proj): lora.Linear(\n",
              "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.1, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                  (lora_magnitude_vector): ModuleDict()\n",
              "                )\n",
              "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10
    },
    {
      "id": "dcfba9c5-846f-4ff9-8756-5179b25c7932",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Snousnou/Moroccan-Darija-ASR\")\n",
        "example = ds[\"train\"][2]  # index 2 pour \u201cbghit nkhles dariba\u201d\n",
        "\n",
        "print(\"Audio dur\u00e9e:\", example[\"audioduration\"], \"s\")\n",
        "print(\"Transcription:\", example[\"text\"])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.577578Z",
          "iopub.status.idle": "2025-07-17T11:45:28.577915Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.577731Z",
          "shell.execute_reply": "2025-07-17T11:45:28.577748Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481,
          "referenced_widgets": [
            "6190347791a84e0a956824148ad553b7",
            "3a187e5a9b8941d0aaa18ad4811f32ea",
            "ecacec627c8044b2879d683281f8ee9b",
            "138bdd8cfcc74d46a3fe4a817949f0c3",
            "8e9413f45c6b41538a664b5d8c088901",
            "73f1996bfa39464eb11621f43a07d563",
            "d6da3df2c90a4fac849a4686f5fe8757",
            "23ac029a2a1f4f64a169b8624c51e88f",
            "b65aaa5b44e34334a46acc88fc7d395a",
            "2bc5ed07574f4d11aa389543213e9cb9",
            "a6719bd9c56340fda70d41c36fcdf6b9",
            "c6ab9e406cd2484ba28897dc78d0d72f",
            "84d9a6a73cb04153906d303f23a90874",
            "058f77c4a0e54bf8be71314cc2c198c0",
            "e55c47b9b3d74af5abc07c81c6e719a6",
            "e7554b1a282b4fa4977713fce661f08b",
            "13084c32ddd949d0965c98e61a4954a3",
            "6a3c6b043e304db5aeffcff4ffbdbc9b",
            "42de2033e7f84895b7f4dbe3cbf64ef6",
            "e963af3ca3834d6a9c5abe075a558157",
            "5fba8b1575e14bb38a58fedb2b580cdb",
            "b14ded0ca64d4bf5a435c2b6a3c49850",
            "ad8de7375e804686a4148ec91ea0a9df",
            "ee125f17e3324166b871085b1ef28731",
            "9ee451d93cfe4c50b841dcba34ed470e",
            "ee65a8e8dff046fa98e36731e9b5eb7f",
            "cde31f6a779e47cc987d3a6abd52459b",
            "49ce37995b104ae8b2f070f0249cfd86",
            "28130d47361b438e862ca33ca1531bbf",
            "e9efeae541c84bc1b44d21c5a5897a5d",
            "9ccff39e0abf4bcd9c5f2fed03121b57",
            "892481e346754022bc43f6d6bab1eecb",
            "ba37f80dab9e4e3c9742cf9080fe3b95",
            "e5f9d72bf98647be8da6c951081cd27e",
            "e6668da9e34a406ba26ca48513faca4f",
            "bcaef348ab9a4699b68f7b965143ccbe",
            "1aa4a4148bcf4b6aa4d2c77d3773a5d3",
            "2ab0f577a95943bd995a28fef29e1b6a",
            "a4e5a8cafd6c486080ffcf2bb00dabdd",
            "13719b5c6e3743d284f066daa5973380",
            "139575631cd04cff9a5b1daf7beaf435",
            "0c4a37ac156443ec9547427982795396",
            "7645132c98fe4de1bd58d249fafecbc8",
            "68db7dd3572e4866bbb6b86faede1db7",
            "ac3faf1a4ea44dec83b8533a938a03cb",
            "9549ba55ba9d414896892bee8b8a81cf",
            "68411b1c9a934aef8fe81b5ccafaf7d9",
            "728c1748db9644a294cb899fcd71023f",
            "d3dacf45560b486e8351860925844939",
            "3dc025856d8e4ddb9551de49ada5a0c6",
            "30173ff38ff347e8b7224e40d102076d",
            "628040e7b69146d58f831889faf2bc1b",
            "326783138be241f79da2d257005f5d22",
            "5987454caee54976ba6fcfe902a3d26a",
            "33568b50d677455ca0b9ef6cd314c908",
            "8a0ee01da9474c0c9af03ca6f4fb6680",
            "2d83bb97a809419d9f0d84b42950b6d6",
            "a7dbf2fe16a248fbbe0c2632e1c73918",
            "b9777b08cf32400ca99b1932ac0d87f7",
            "6faceb7cd1c74d66b8e8799949900607",
            "e577ed7f53c146e8b0d1d72a3a236eb2",
            "ac615c99378f45e09e654f2d48171bfe",
            "22324a07628b42848fa4aad48e5c6744",
            "8d1d1b8757f5491f90783805c928b45f",
            "1350bbf942d145e6b45635cf125ed8ed",
            "7b8fd727a71c44bfabc9d98ec3426199",
            "3a9a4ebb38d1412e87656b5f4c993fa4",
            "840395f699414c66b220e9ec2a3d63ee",
            "87ffe5a6ad684299804eb499be654736",
            "e6fca32600fa48dea18d7d90ed57e67d",
            "ef2ec9a7e27643babdd1bc7ec8549fc5",
            "2450cf2a0f7347da89e8f3492ddc6668",
            "ccc8b7fd4c2f4f32861e9d8bf7bd92a3",
            "0ef481508e9b4c1a8197f1f4716ac601",
            "8f9c5e00024a45f1aa1b11c5f86673d5",
            "a88e310929054c8c91d55bea947c0d6a",
            "eb2dac811afe45b39bb22df1e49b4c94",
            "b8e5c35d04614b7dbbf1b01179bef383",
            "00f5175e941d4d6a923be213ca0068f2",
            "455624dfe5284dacb0f7ab675f74c2e2",
            "82f543f959784156a6c8708714d28ad3",
            "dbfdf4de7d7645f3b5bc06e68dafdcd3",
            "c086056fad8c4befbed148f8d4e691e2",
            "d989b8f71f484598abe268319e875a6a",
            "21f7048b76db46e186a9316ef4a7dc20",
            "87f6b6dc8a6345818ddb1a3a0639d33c",
            "0556dad47e964b389b632ac4619db93c",
            "12d1bd66293a4f908979685725290769",
            "3863c99a090a431ea3d1dcc24bf632a1",
            "6e020780d7854411a0d3f398292ee6b3",
            "8bbb2e8c42f740e89a28a02908987c63",
            "93fd79eb90a548f99cce7af942a8dc7f",
            "c1b7264fb18c4ebcb583626e9de09459",
            "c84154cf5f774cd1a3e88bb1baba596f",
            "b18ce68d68c148989b3f962478d1c79d",
            "71d361f97ab54994a17e9bcef1c146d7",
            "92d7a797469c469491a671bfefddbff4",
            "deea9c0867e049268272c8c0993abfef",
            "947aa1636356433593760a36d41239d9"
          ]
        },
        "id": "dcfba9c5-846f-4ff9-8756-5179b25c7932",
        "outputId": "c0d26cf9-c27b-4439-991c-8f1ec27f87f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/590 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6190347791a84e0a956824148ad553b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6ab9e406cd2484ba28897dc78d0d72f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/109k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad8de7375e804686a4148ec91ea0a9df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/298k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5f9d72bf98647be8da6c951081cd27e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/78.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac3faf1a4ea44dec83b8533a938a03cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a0ee01da9474c0c9af03ca6f4fb6680"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a9a4ebb38d1412e87656b5f4c993fa4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8e5c35d04614b7dbbf1b01179bef383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3863c99a090a431ea3d1dcc24bf632a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'audioduration'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-2943950056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# index 2 pour \u201cbghit nkhles dariba\u201d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio dur\u00e9e:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audioduration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transcription:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'audioduration'"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "id": "c1b46802-7177-473c-bffa-4f7d53a55440",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Snousnou/Moroccan-Darija-ASR\")\n",
        "example = ds[\"train\"][2]\n",
        "print(example.keys())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.578798Z",
          "iopub.status.idle": "2025-07-17T11:45:28.579063Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.578939Z",
          "shell.execute_reply": "2025-07-17T11:45:28.578951Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b46802-7177-473c-bffa-4f7d53a55440",
        "outputId": "d642ef9a-932d-4a6f-ceda-4c23af5c16fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['file', 'text'])\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "id": "3664ed46-f336-4cfb-8798-54f5fdd99a95",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# Charger dataset\n",
        "ds = load_dataset(\"Snousnou/Moroccan-Darija-ASR\")\n",
        "example = ds[\"train\"][2]\n",
        "\n",
        "print(\"Cl\u00e9s disponibles :\", example.keys())\n",
        "print(\"R\u00e9f\u00e9rence :\", example[\"text\"])\n",
        "\n",
        "# R\u00e9cup\u00e9rer audio (array + sample_rate)\n",
        "audio_array = example[\"file\"][\"array\"]\n",
        "sample_rate = example[\"file\"][\"sampling_rate\"]\n",
        "\n",
        "# Charger mod\u00e8le\n",
        "processor = WhisperProcessor.from_pretrained(\"./whisper-darja-lora-final\")\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "model = PeftModel.from_pretrained(base_model, \"./whisper-darja-lora-final\")\n",
        "model.eval()\n",
        "\n",
        "# Pr\u00e9parer features\n",
        "inputs = processor(audio_array, sampling_rate=sample_rate, return_tensors=\"pt\").input_features.to(model.device)\n",
        "\n",
        "# G\u00e9n\u00e9rer transcription\n",
        "with torch.no_grad():\n",
        "   generated_ids = model.base_model.generate(\n",
        "    inputs,\n",
        "    max_length=128,\n",
        "    forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        ")\n",
        "\n",
        "\n",
        "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(\"Pr\u00e9diction :\", transcription)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.579757Z",
          "iopub.status.idle": "2025-07-17T11:45:28.579992Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.579877Z",
          "shell.execute_reply": "2025-07-17T11:45:28.579889Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3664ed46-f336-4cfb-8798-54f5fdd99a95",
        "outputId": "be602978-2af6-4e40-ae18-d12ab8d54066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cl\u00e9s disponibles : dict_keys(['file', 'text'])\n",
            "R\u00e9f\u00e9rence : bghit nkhles dariba\n",
            "Pr\u00e9diction : \u062a\u063a\u064a\u0637 \u0646\u062e\u0644\u0635 \u0627\u0644\u0637\u0631\u064a\u0628\u0629\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "id": "d187b14d-5ad6-4b9e-ac7e-60451a00f70a",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Charger dataset et un exemple\n",
        "ds = load_dataset(\"Snousnou/Moroccan-Darija-ASR\")\n",
        "example = ds[\"train\"][2]\n",
        "audio_array = example[\"file\"][\"array\"]\n",
        "sample_rate = example[\"file\"][\"sampling_rate\"]\n",
        "\n",
        "# Charger processor et mod\u00e8le de base Whisper-small\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "base_model.eval()\n",
        "\n",
        "# Pr\u00e9parer les features\n",
        "inputs = processor(audio_array, sampling_rate=sample_rate, return_tensors=\"pt\").input_features\n",
        "\n",
        "# G\u00e9n\u00e9rer transcription avec Whisper-small (base)\n",
        "with torch.no_grad():\n",
        "    generated_ids_base = base_model.generate(\n",
        "        inputs,\n",
        "        max_length=128,\n",
        "        forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        "    )\n",
        "transcription_base = processor.batch_decode(generated_ids_base, skip_special_tokens=True)[0]\n",
        "\n",
        "print(\"\ud83d\udcdd R\u00e9f\u00e9rence :\", example[\"text\"])\n",
        "print(\"\ud83e\udd16 Whisper-small base :\", transcription_base)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.580457Z",
          "iopub.status.idle": "2025-07-17T11:45:28.580772Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.580595Z",
          "shell.execute_reply": "2025-07-17T11:45:28.580609Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d187b14d-5ad6-4b9e-ac7e-60451a00f70a",
        "outputId": "69590c9d-ec7c-4012-8d38-03523e56d9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udcdd R\u00e9f\u00e9rence : bghit nkhles dariba\n",
            "\ud83e\udd16 Whisper-small base :  \u0628\u0631\u064a\u0628\u0646 \u062e\u0644\u0635 \u0628\u0637\u0627\u0631\u064a\u0628\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "id": "38eb0b14-ce91-4024-813a-565d3ee334ee",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "from jiwer import wer\n",
        "\n",
        "# Charger dataset (tu peux changer 'train' en 'test' si tu pr\u00e9f\u00e8res)\n",
        "ds = load_dataset(\"Snousnou/Moroccan-Darija-ASR\", split=\"train\")\n",
        "\n",
        "# Charger processor et mod\u00e8les\n",
        "processor = WhisperProcessor.from_pretrained(\"./whisper-darja-lora-final\")\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "base_model.eval()\n",
        "\n",
        "base_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Charger mod\u00e8le LoRA\n",
        "base_model_for_lora = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "model_lora = PeftModel.from_pretrained(base_model_for_lora, \"./whisper-darja-lora-final\")\n",
        "model_lora.eval()\n",
        "model_lora.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Limite le nombre d'exemples pour test rapide\n",
        "max_examples = 10\n",
        "\n",
        "wers_base = []\n",
        "wers_lora = []\n",
        "\n",
        "for i, example in enumerate(ds):\n",
        "    if i >= max_examples:\n",
        "        break\n",
        "\n",
        "    audio = example[\"file\"][\"array\"]\n",
        "    sample_rate = example[\"file\"][\"sampling_rate\"]\n",
        "    reference = example[\"text\"]\n",
        "\n",
        "    inputs = processor(audio, sampling_rate=sample_rate, return_tensors=\"pt\").input_features.to(device)\n",
        "\n",
        "    # Base model generate\n",
        "    with torch.no_grad():\n",
        "        generated_ids_base = base_model.generate(\n",
        "            inputs,\n",
        "            max_length=128,\n",
        "            forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        "        )\n",
        "    pred_base = processor.batch_decode(generated_ids_base, skip_special_tokens=True)[0]\n",
        "\n",
        "    # LoRA model generate (attention \u00e0 generate sur base_model)\n",
        "    with torch.no_grad():\n",
        "        generated_ids_lora = model_lora.base_model.generate(\n",
        "            inputs,\n",
        "            max_length=128,\n",
        "            forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        "        )\n",
        "    pred_lora = processor.batch_decode(generated_ids_lora, skip_special_tokens=True)[0]\n",
        "\n",
        "    # Calcul WER (tu peux normaliser les textes si besoin)\n",
        "    wer_base = wer(reference, pred_base)\n",
        "    wer_lora = wer(reference, pred_lora)\n",
        "\n",
        "    wers_base.append(wer_base)\n",
        "    wers_lora.append(wer_lora)\n",
        "\n",
        "    print(f\"\\nExemple {i+1}:\")\n",
        "    print(\"R\u00e9f\u00e9rence     :\", reference)\n",
        "    print(\"Pr\u00e9diction Base :\", pred_base)\n",
        "    print(f\"WER Base      : {wer_base:.3f}\")\n",
        "    print(\"Pr\u00e9diction LoRA :\", pred_lora)\n",
        "    print(f\"WER LoRA      : {wer_lora:.3f}\")\n",
        "\n",
        "print(\"\\n=== R\u00e9sultats moyens ===\")\n",
        "print(f\"WER moyen Base : {sum(wers_base)/len(wers_base):.3f}\")\n",
        "print(f\"WER moyen LoRA : {sum(wers_lora)/len(wers_lora):.3f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.584469Z",
          "iopub.status.idle": "2025-07-17T11:45:28.584956Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.584733Z",
          "shell.execute_reply": "2025-07-17T11:45:28.584753Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38eb0b14-ce91-4024-813a-565d3ee334ee",
        "outputId": "786d6f51-2c1e-46a7-e2ed-0e1f00defa19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemple 1:\n",
            "R\u00e9f\u00e9rence     : bghit nsift lflous\n",
            "Pr\u00e9diction Base :  \u0648\u0646\u062d\u0646 \u0646\u0642\u0648\u0645 \u0628\u0639\u0645\u0644 \u0633\u0641\u062a \u0627\u0644\u0641\u0644\u0648\u0633\n",
            "WER Base      : 1.667\n",
            "Pr\u00e9diction LoRA : \u0628\u063a\u064a\u062a \u0646\u0633\u0627\u0641\u0637 \u0627\u0644\u0641\u0644\u0648\u0633\n",
            "WER LoRA      : 1.000\n",
            "\n",
            "Exemple 2:\n",
            "R\u00e9f\u00e9rence     : ch7al f solde\n",
            "Pr\u00e9diction Base :  \u0634\u0647\u0644 \u0641\u064a \u0627\u0644\u0633\u0648\u0644\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u0634\u062d\u0627\u0644 \u0641\u0627\u0644\u0633\u0648\u0644\n",
            "WER LoRA      : 1.000\n",
            "\n",
            "Exemple 3:\n",
            "R\u00e9f\u00e9rence     : bghit nkhles dariba\n",
            "Pr\u00e9diction Base :  \u0628\u0631\u064a\u0628\u0646 \u062e\u0644\u0635 \u0628\u0637\u0627\u0631\u064a\u0628\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u062a\u063a\u064a\u0637 \u0646\u062e\u0644\u0635 \u0627\u0644\u0637\u0631\u064a\u0628\u0629\n",
            "WER LoRA      : 1.000\n",
            "\n",
            "Exemple 4:\n",
            "R\u00e9f\u00e9rence     : ch7al flcompte\n",
            "Pr\u00e9diction Base :  \u0634\u0647\u0644 \u0639\u0646\u062f\u064a \u0641\u064a \u0627\u0644\u0643\u0646\u062a\n",
            "WER Base      : 2.000\n",
            "Pr\u00e9diction LoRA : \u0634\u062d\u0627\u0644 \u0639\u0646\u062f\u064a \u0641\u064a \u0627\u0644\u0643\u0646\u062a\n",
            "WER LoRA      : 2.000\n",
            "\n",
            "Exemple 5:\n",
            "R\u00e9f\u00e9rence     : bghit nkhrej lflous\n",
            "Pr\u00e9diction Base :  \u0631\u064a\u062a\u0645 \u062e\u0631\u0632\u0631 \u0641\u0644\u0648\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u063a\u064a\u0637 \u0646\u062e\u0631\u062c \u0646\u0634\u0641\u0648\n",
            "WER LoRA      : 1.000\n",
            "\n",
            "Exemple 6:\n",
            "R\u00e9f\u00e9rence     : bghit nkhles lma o do\n",
            "Pr\u00e9diction Base :  \u0628\u0631\u064a\u062f \u0646\u062e\u0644\u0635\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u0628\u063a\u064a\u062a \u0646\u062e\u0644\u0635\n",
            "WER LoRA      : 1.000\n",
            "\n",
            "=== R\u00e9sultats moyens ===\n",
            "WER moyen Base : 1.278\n",
            "WER moyen LoRA : 1.167\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "id": "2f2e79d9-19e5-46ab-a0fb-65d28c882e94",
      "cell_type": "code",
      "source": [
        "def simple_arabic_to_latin(text):\n",
        "    mapping = {\n",
        "        '\u0628': 'b', '\u0631': 'r', '\u064a': 'y', '\u062f': 'd',\n",
        "        '\u0646': 'n', '\u062e': 'kh', '\u0644': 'l', '\u0635': 's',\n",
        "        '\u0637': 't', '\u0627': 'a', '\u062d': 'h', '\u0642': 'q',\n",
        "        '\u0633': 's', '\u0645': 'm', '\u0648': 'w', '\u0641': 'f',\n",
        "        '\u0634': 'sh', '\u0639': 'a', '\u063a': 'gh', '\u0643': 'k',\n",
        "        '\u062a': 't', '\u062c': 'j', '\u0630': 'dh', '\u0632': 'z',\n",
        "        '\u0636': 'd', '\u0638': 'z', '\u0647': 'h', '\u064a': 'y',\n",
        "        '\u0621': \"'\", '\u0624': 'w', '\u0626': 'y',\n",
        "        # ajoute les autres lettres si besoin\n",
        "    }\n",
        "    latin = \"\"\n",
        "    for ch in text:\n",
        "        latin += mapping.get(ch, ch)  # si lettre inconnue, la garder brute\n",
        "    return latin\n",
        "\n",
        "# Exemple d\u2019utilisation\n",
        "ar_text = \"\u0628\u0631\u064a\u062f \u0646\u062e\u0644\u0635\"\n",
        "print(simple_arabic_to_latin(ar_text))  # devrait afficher : brid nkhls\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.585584Z",
          "iopub.status.idle": "2025-07-17T11:45:28.585972Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.585769Z",
          "shell.execute_reply": "2025-07-17T11:45:28.585787Z"
        },
        "id": "2f2e79d9-19e5-46ab-a0fb-65d28c882e94"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f3c46a10-886f-4c8d-8ef1-94f9671a9436",
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Contenu de ./whisper-darja-lora :\")\n",
        "print(os.listdir(\"./whisper-darja-lora\"))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.58654Z",
          "iopub.status.idle": "2025-07-17T11:45:28.586923Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.586735Z",
          "shell.execute_reply": "2025-07-17T11:45:28.586753Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3c46a10-886f-4c8d-8ef1-94f9671a9436",
        "outputId": "ccbbb2a5-e9c4-4ee6-c606-4ebfe74c0eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contenu de ./whisper-darja-lora :\n",
            "['checkpoint-3180', 'checkpoint-2000', 'checkpoint-1000', 'checkpoint-1500', 'checkpoint-2500', 'checkpoint-3000', 'checkpoint-500']\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "id": "1e2298a3-6234-46d2-aadd-5990e5c7e79e",
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"whisper-darja-lora-final\", 'zip', output_dir)\n",
        "print(\"Archive whisper-darja-lora.zip cr\u00e9\u00e9e.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.593892Z",
          "iopub.status.idle": "2025-07-17T11:45:28.59441Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.59415Z",
          "shell.execute_reply": "2025-07-17T11:45:28.594173Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e2298a3-6234-46d2-aadd-5990e5c7e79e",
        "outputId": "8f176f1e-b91d-4ad9-b978-6cf797a70890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive whisper-darja-lora.zip cr\u00e9\u00e9e.\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "id": "48246ac0-2978-4bf5-8e6b-496ef1c6fb64",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "from jiwer import wer\n",
        "import types\n",
        "\n",
        "ds = load_dataset(\"atlasia/DODa-audio-dataset\", split=\"train\")\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"./whisper-darja-lora-final\")\n",
        "\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "base_model.eval()\n",
        "base_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "base_model_for_lora = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "model_lora = PeftModel.from_pretrained(base_model_for_lora, \"./whisper-darja-lora-final\")\n",
        "model_lora.eval()\n",
        "model_lora.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Patch n\u00e9cessaire sur forward\n",
        "base_forward = model_lora.base_model.forward\n",
        "def base_model_forward_patch(self, *args, **kwargs):\n",
        "    for arg in [\"input_ids\", \"inputs_embeds\"]:\n",
        "        if arg in kwargs:\n",
        "            kwargs.pop(arg)\n",
        "    return base_forward(*args, **kwargs)\n",
        "model_lora.base_model.forward = types.MethodType(base_model_forward_patch, model_lora.base_model)\n",
        "\n",
        "max_examples = 10\n",
        "\n",
        "wers_base = []\n",
        "wers_lora = []\n",
        "\n",
        "for i, example in enumerate(ds):\n",
        "    if i >= max_examples:\n",
        "        break\n",
        "\n",
        "    audio = example[\"audio\"][\"array\"]\n",
        "    sample_rate = example[\"audio\"][\"sampling_rate\"]\n",
        "    reference = example[\"darija_Arab_new\"]\n",
        "\n",
        "    inputs = processor(audio, sampling_rate=sample_rate, return_tensors=\"pt\").input_features.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids_base = base_model.generate(\n",
        "            inputs,\n",
        "            max_length=128,\n",
        "            forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        "        )\n",
        "    pred_base = processor.batch_decode(generated_ids_base, skip_special_tokens=True)[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids_lora = model_lora.base_model.generate(\n",
        "            input_features=inputs,\n",
        "            max_length=128,\n",
        "            forced_decoder_ids=processor.get_decoder_prompt_ids(language=\"ar\", task=\"transcribe\")\n",
        "        )\n",
        "    pred_lora = processor.batch_decode(generated_ids_lora, skip_special_tokens=True)[0]\n",
        "\n",
        "    wer_base = wer(reference, pred_base)\n",
        "    wer_lora = wer(reference, pred_lora)\n",
        "\n",
        "    wers_base.append(wer_base)\n",
        "    wers_lora.append(wer_lora)\n",
        "\n",
        "    print(f\"\\nExemple {i+1}:\")\n",
        "    print(\"R\u00e9f\u00e9rence     :\", reference)\n",
        "    print(\"Pr\u00e9diction Base :\", pred_base)\n",
        "    print(f\"WER Base      : {wer_base:.3f}\")\n",
        "    print(\"Pr\u00e9diction LoRA :\", pred_lora)\n",
        "    print(f\"WER LoRA      : {wer_lora:.3f}\")\n",
        "\n",
        "print(\"\\n=== R\u00e9sultats moyens ===\")\n",
        "print(f\"WER moyen Base : {sum(wers_base)/len(wers_base):.3f}\")\n",
        "print(f\"WER moyen LoRA : {sum(wers_lora)/len(wers_lora):.3f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-17T11:45:28.595174Z",
          "iopub.status.idle": "2025-07-17T11:45:28.595537Z",
          "shell.execute_reply.started": "2025-07-17T11:45:28.595367Z",
          "shell.execute_reply": "2025-07-17T11:45:28.595382Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48246ac0-2978-4bf5-8e6b-496ef1c6fb64",
        "outputId": "c2ed27bb-f3c1-471c-baba-9d4def5ed2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemple 1:\n",
            "R\u00e9f\u00e9rence     : \u0647\u0648\u0645\u0627 \u0645\u062e\u0628\u064a\u064a\u0646 \u0634\u064a \u062d\u0627\u062c\u0629 \u0627\u0646\u0627 \u0645\u062a\u064a\u0642\u0646\n",
            "Pr\u00e9diction Base :  \u0647\u0645 \u0645\u062e\u0628\u0646\u0634\u064a \u062d\u0627\u062c\u0629 \u0623\u0646\u0627 \u0645\u062a\u0642\u0646\n",
            "WER Base      : 0.833\n",
            "Pr\u00e9diction LoRA : \u0647\u0645\u0627 \u0645\u062e\u0628\u064a\u0646 \u0634\u064a \u062d\u0627\u062c\u0629 \u0627\u0646\u0627 \u0645\u062a\u0642\u0646\n",
            "WER LoRA      : 0.500\n",
            "\n",
            "Exemple 2:\n",
            "R\u00e9f\u00e9rence     : \u0628\u0627\u064a\u0646\u0629 \u0647\u0648\u0645\u0627 \u0643\u064a\u062d\u0627\u0648\u0644\u0648 \u064a\u0628\u0642\u0627\u0648 \u0645\u0628\u0631\u062f\u064a\u0646\n",
            "Pr\u00e9diction Base :  \u0628\u064a\u0646\u0647\u0645\u0627 \u0643\u062d\u0648\u0644\u0648\u0627 \u0628\u0642\u0627\u0645 \u0628\u0631\u062f\u064a\u0646\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u0628\u0639\u064a\u0646\u0629 \u0647\u0645\u0627 \u0643\u064a\u062d\u0627\u0648\u0644\u0648 \u064a\u0628\u0642\u0627\u0647\u0645 \u0628\u0631\u062f\u064a\u0646\n",
            "WER LoRA      : 0.800\n",
            "\n",
            "Exemple 3:\n",
            "R\u00e9f\u00e9rence     : \u0644\u0648\u0637\u064a\u0644\u0627\u062a \u0645\u0628\u064a\u0646\u0627\u0634 \u0641\u064a\u0647\u0645 \u0645\u0631\u064a\u062d\u064a\u0646 \u0628\u0632\u0627\u0641\n",
            "Pr\u00e9diction Base :  \u0644\u0648 \u0637\u064a\u0644\u0627\u062a \u0645\u0627 \u0628\u064a\u0646\u0627\u0634 \u0641\u064a\u0647\u0645 \u0645\u0648\u0631\u062d\u064a\u0646 \u0628\u0627\u0644\u0632\u064a\u0641\n",
            "WER Base      : 1.200\n",
            "Pr\u00e9diction LoRA : \u0627\u0644\u0648\u0637\u064a\u0644\u0627\u062a \u0645\u0628\u064a\u0646\u0627\u0634 \u0641\u064a\u0647\u0645 \u0645\u0631\u064a\u062d\u064a\u0646 \u0628\u0632\u0627\u0641\n",
            "WER LoRA      : 0.200\n",
            "\n",
            "Exemple 4:\n",
            "R\u00e9f\u00e9rence     : \u063a\u0627\u0644\u0628\u0627 \u063a\u064a\u062c\u0631\u064a\u0648 \u0639\u0644\u064a\u0647 \u0645\u0646 \u0627\u0644\u062e\u062f\u0645\u0629\n",
            "Pr\u00e9diction Base :  \u063a\u0627\u0644\u0628\u0627\u064b \u063a\u064a\u0631\u0648\u0627 \u0639\u0644\u064a\u0647\u0645 \u0627\u0644\u062e\u062f\u0645\u0629\n",
            "WER Base      : 0.800\n",
            "Pr\u00e9diction LoRA : \u063a\u0627\u0644\u0628\u0627 \u0646\u063a\u064a\u062c\u0631\u064a\u0648 \u0639\u0644\u064a\u0647 \u0645\u0646 \u0627\u0644\u062e\u062f\u0645\u0629\n",
            "WER LoRA      : 0.200\n",
            "\n",
            "Exemple 5:\n",
            "R\u00e9f\u00e9rence     : \u0637\u0628\u0639\u0627 \u0631\u0627\u0647 \u0645\u0643\u062a\u0626\u0628\n",
            "Pr\u00e9diction Base :  \u0637\u0628\u0639\u0627 \u0644\u0646\u0631\u062d\u0645\u0643 \u062a\u0627\u0626\u0628\n",
            "WER Base      : 0.667\n",
            "Pr\u00e9diction LoRA : \u0637\u0628\u0639\u0627 \u0631\u0627\u0647 \u0645\u0643\u062a\u0627\u0628\n",
            "WER LoRA      : 0.333\n",
            "\n",
            "Exemple 6:\n",
            "R\u00e9f\u00e9rence     : \u0643\u064a\u0628\u0627\u0646 \u0644\u064a\u0627 \u063a\u0646\u0645\u0634\u064a\n",
            "Pr\u00e9diction Base :  \u0643\u064a \u0628\u0627\u0644\u0644\u064a\u063a\u0627 \u0646\u0645\u0634\u064a\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u0643\u064a\u0628\u0627\u0646 \u0644\u064a\u0627 \u063a\u0646\u0645\u0634\u064a\n",
            "WER LoRA      : 0.000\n",
            "\n",
            "Exemple 7:\n",
            "R\u00e9f\u00e9rence     : \u0627\u0631\u0627 \u0644\u064a\u0627 \u062f\u0627\u0643 \u0627\u0644\u0635\u0627\u0643\n",
            "Pr\u00e9diction Base :  \u0623\u0631\u0627\u0644\u064a \u062f\u0643\u0633\u0627\u0643\n",
            "WER Base      : 1.000\n",
            "Pr\u00e9diction LoRA : \u0627\u0631\u0627 \u0644\u064a\u0627 \u062f\u0627\u0643\u0633\u0627\u0643\n",
            "WER LoRA      : 0.500\n",
            "\n",
            "Exemple 8:\n",
            "R\u00e9f\u00e9rence     : \u063a\u0646\u0645\u0631\u0636\n",
            "Pr\u00e9diction Base :  \u063a\u0627\u0646 \u0645\u0631\u062f\n",
            "WER Base      : 2.000\n",
            "Pr\u00e9diction LoRA : \u063a\u0646\u0645\u0631\u0636\n",
            "WER LoRA      : 0.000\n",
            "\n",
            "Exemple 9:\n",
            "R\u00e9f\u00e9rence     : \u0643\u0646\u062a \u062f\u064a\u0645\u0627 \u0639\u0627\u0631\u0641 \u0627\u0646\u0647\u0627 \u0628\u063a\u0627\u062a\u0646\u0627 \u0646\u0645\u0648\u062a\u0648\n",
            "Pr\u00e9diction Base :  \u0643\u0646\u062a \u062f\u064a \u0645\u0639\u0631\u0641 \u0623\u0646\u0647\u0627 \u0628\u063a\u062a\u0646\u0627 \u0627\u0644\u0645\u0648\u062a\u0648\n",
            "WER Base      : 0.833\n",
            "Pr\u00e9diction LoRA : \u0643\u0646\u062f\u064a \u0645\u0639\u0627\u0631\u0641 \u0627\u0646\u0647\u0627 \u0628\u063a\u062a\u0646\u0627 \u0627\u0644\u0645\u0648\u062a\u0648\n",
            "WER LoRA      : 0.833\n",
            "\n",
            "Exemple 10:\n",
            "R\u00e9f\u00e9rence     : \u0628\u063a\u064a\u062a \u0646\u0639\u0631\u0641 \u0634\u062d\u0627\u0644 \u0628\u0642\u0649 \u0644\u064a\u0627 \u062f\u064a\u0627\u0644 \u0627\u0644\u0648\u0642\u062a \u0628\u0627\u0634 \u0646\u0642\u0631\u0627\n",
            "Pr\u00e9diction Base :  \u0623\u0631\u064a\u062f \u0623\u0646 \u0646\u0639\u0631\u0641 \u0634\u062d\u0644 \u0628\u0642\u0627\u0644\u064a\u0629 \u0627\u0644\u0648\u0642\u062a \u0628\u0634\u0646\u0642\u0631\u0627\n",
            "WER Base      : 0.889\n",
            "Pr\u00e9diction LoRA : \u0628\u063a\u064a\u062a \u0646\u0639\u0631\u0641\u0634 \u062d\u0627\u0644 \u0628\u0642\u0627\u0644\u064a\u0629 \u062f\u064a\u0627\u0644 \u0627\u0644\u0648\u0642\u062a \u0628\u0627\u0634 \u0646\u0642\u0631\u0627\n",
            "WER LoRA      : 0.444\n",
            "\n",
            "=== R\u00e9sultats moyens ===\n",
            "WER moyen Base : 1.022\n",
            "WER moyen LoRA : 0.381\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "id": "df523896-3ecf-406b-b417-dac06575073f",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "df523896-3ecf-406b-b417-dac06575073f"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}